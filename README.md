
# 
ğ“”ğ“¶ğ“¸ğ“½ğ“²ğ“¦ğ“ªğ“¿ğ“® : ğ“¡ğ“²ğ“­ğ“® ğ“½ğ“±ğ“® ğ“£ğ“²ğ“­ğ“® ğ“¸ğ“¯ ğ“—ğ“¾ğ“¶ğ“ªğ“· ğ“”ğ”ğ“¹ğ“»ğ“®ğ“¼ğ“¼ğ“²ğ“¸ğ“·ğ“¼ğŸ˜Š

ğŸ“– ğ‘¶ğ’—ğ’†ğ’“ğ’—ğ’Šğ’†ğ’˜

This project showcases a Facial Emotion Detection System built using the ResEmotiNet model trained on the FER2013 dataset. The system can identify emotions from images, videos, and live webcam feeds, offering real-time emotion recognition functionality.

The system recognizes the following 7 emotions:

Happiness ğŸ˜€

Surprise ğŸ˜¦

Anger ğŸ˜ 

Sadness â˜¹ï¸

Disgust ğŸ¤¢

Fear ğŸ˜¨

Neutral ğŸ˜

A Streamlit interface provides an intuitive user experience, allowing users to upload images or videos or process live webcam feeds seamlessly.

ğŸ”§ ğ‘­ğ’†ğ’‚ğ’•ğ’–ğ’“ğ’†ğ’”

Emotion Detection from Images: Upload an image to detect emotions in real-time.

Emotion Detection from Videos: Process video files to identify emotions in every detected face.

Live Webcam Feed: Use your webcam to detect and classify emotions dynamically.

Streamlit Interface: User-friendly web application for input and visualization.

Haar Cascade Classifier: Efficient face detection in images and videos.

Detailed Emotion Scores: Probability scores for each emotion displayed alongside the highest-confidence prediction.

ğŸ–¥ï¸ ğ‘»ğ’†ğ’„ğ’‰ğ’ğ’ğ’ğ’ğ’ˆğ’š ğ‘ºğ’•ğ’‚ğ’„ğ’Œ

Core Components

Deep Learning Framework: PyTorch

Model: ResEmotiNet (a custom deep learning model)

Dataset: FER2013, containing 7 emotion classes

ğ‘¨ğ’…ğ’…ğ’Šğ’•ğ’Šğ’ğ’ğ’‚ğ’ ğ‘³ğ’Šğ’ƒğ’“ğ’‚ğ’“ğ’Šğ’†ğ’”

OpenCV: For image and video processing, and webcam integration

Streamlit: Interactive user interface

Torchvision: For pre-processing and data transformations

ğŸ› ï¸ ğ‘¯ğ’ğ’˜ ğ‘°ğ’• ğ‘¾ğ’ğ’“ğ’Œğ’”

Face Detection:
The Haar Cascade Classifier detects faces in the input image or video frame.

Emotion Classification:
The detected face is passed through the ResEmotiNet model, which predicts emotion probabilities.

Visualization:
The detected emotion (with the highest confidence) and corresponding scores for all emotions are displayed on the output.

ğŸ“ ğ‘¼ğ’”ğ’‚ğ’ˆğ’† ğ‘°ğ’ğ’”ğ’•ğ’“ğ’–ğ’„ğ’•ğ’Šğ’ğ’ğ’”

1.Create a Conda environment.

```bash

ğ—°ğ—¼ğ—»ğ—±ğ—® ğ—°ğ—¿ğ—²ğ—®ğ˜ğ—² --ğ—» "ğ—³ğ—²ğ—¿"
ğ—°ğ—¼ğ—»ğ—±ğ—® ğ—®ğ—°ğ˜ğ—¶ğ˜ƒğ—®ğ˜ğ—² ğ—³ğ—²ğ—¿

```

2. Install Python v3.8 using Conda.
   
```bash

ğ—°ğ—¼ğ—»ğ—±ğ—® ğ—¶ğ—»ğ˜€ğ˜ğ—®ğ—¹ğ—¹ ğ—½ğ˜†ğ˜ğ—µğ—¼ğ—»=ğŸ¯.ğŸ´

```
3. Clone the Repository
   
```bash

ğ—´ğ—¶ğ˜ ğ—°ğ—¹ğ—¼ğ—»ğ—² ğ—µğ˜ğ˜ğ—½ğ˜€://ğ—´ğ—¶ğ˜ğ—µğ˜‚ğ—¯.ğ—°ğ—¼ğ—º/ğ—®ğ—¯ğ—µğ—¶ğ—»ğ—®ğ˜†ğ—®-ğ—½ğ—®ğ—¶ğ—¹ğ—¹ğ—®/ğ—˜ğ—ºğ—¼ğ˜ğ—¶ğ—ªğ—®ğ˜ƒğ—²  
ğ—°ğ—± ğ—˜ğ—ºğ—¼ğ˜ğ—¶ğ—ªğ—®ğ˜ƒğ—²

```

4. Install Dependencies

```bash

ğ—½ğ—¶ğ—½ ğ—¶ğ—»ğ˜€ğ˜ğ—®ğ—¹ğ—¹ -ğ—¿ ğ—¿ğ—²ğ—¾ğ˜‚ğ—¶ğ—¿ğ—²ğ—ºğ—²ğ—»ğ˜ğ˜€.ğ˜ğ˜…ğ˜

```

5. Run the file.

```bash

ğ—°ğ—± ğ˜ğ—¿ğ—®ğ—¶ğ—»_ğ—³ğ—¶ğ—¹ğ—²ğ˜€
ğ—½ğ˜†ğ˜ğ—µğ—¼ğ—» ğ˜ğ—¿ğ—®ğ—¶ğ—».ğ—½ğ˜†

```

6. Run the Application

Launch the Streamlit app:

```bash

ğ˜€ğ˜ğ—¿ğ—²ğ—®ğ—ºğ—¹ğ—¶ğ˜ ğ—¿ğ˜‚ğ—» ğ—˜ğ—ºğ—¼ğ˜ğ—¶ğ—ªğ—®ğ˜ƒğ—²_ğ—®ğ—½ğ—½.ğ—½ğ˜†

```

ğŸ—‚ï¸ ğ‘°ğ’ğ’‘ğ’–ğ’• ğ‘´ğ’ğ’…ğ’†ğ’”

Image Upload: Drag and drop an image file into the interface for analysis.

Video Upload: Upload a video to process frame-by-frame emotion detection.

Webcam Input: Activate your webcam and see real-time emotion detection.

ğŸ“Š ğ‘«ğ’‚ğ’•ğ’‚ğ’”ğ’†ğ’• ğ‘°ğ’ğ’‡ğ’ğ’“ğ’ğ’‚ğ’•ğ’Šğ’ğ’

The FER2013 dataset is widely used for facial expression recognition tasks. 
It includes:
35,887 grayscale images (48x48 pixels each)
7 emotion classes: Happiness, Surprise, Anger, Sadness, Disgust, Fear, and Neutral

ğŸ’» ğ‘ºğ’„ğ’“ğ’†ğ’†ğ’ğ’”ğ’‰ğ’ğ’•ğ’”

Image Input: Emotion detection and probabilities displayed on the processed image.

Video Input: Real-time video frame processing with emotion labels.

Webcam Feed: Live detection with bounding boxes and emotion predictions.

ğŸŒŸ ğ‘¨ğ’„ğ’Œğ’ğ’ğ’˜ğ’ğ’†ğ’…ğ’ˆğ’†ğ’ğ’†ğ’ğ’•ğ’”

FER2013 Dataset: FER2013 Kaggle

OpenCV Library for efficient image processing

Streamlit for an interactive interface
