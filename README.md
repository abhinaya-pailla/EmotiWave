<<<<<<< HEAD
# ResEmoteNet: Bridging Accuracy and Loss Reduction in Facial Emotion Recognition

[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/resemotenet-bridging-accuracy-and-loss/facial-expression-recognition-on-fer2013)](https://paperswithcode.com/sota/facial-expression-recognition-on-fer2013?p=resemotenet-bridging-accuracy-and-loss)

A new network that helps in extracting facial features and predict the emotion labels.

The emotion labels in this project are:
 - Happiness ðŸ˜€
 - Surprise ðŸ˜¦
 - Anger ðŸ˜ 
 - Sadness â˜¹ï¸
 - Disgust ðŸ¤¢
 - Fear ðŸ˜¨
 - Neutral ðŸ˜


## Table of Content:

 - [Installation](#installation)
 - [Usage](#usage)
 - [Checkpoints](#checkpoints)
 - [Results](#results)
 - [License](#license)


## Installation

1. Create a Conda environment.
```bash
conda create --n "fer"
conda activate fer
```

2. Install Python v3.8 using Conda.
```bash
conda install python=3.8
```

3. Clone the repository.
```bash
git clone https://github.com/ArnabKumarRoy02/ResEmoteNet.git
```

4. Install the required libraries.
```bash
pip install -r requirement.txt
```

## Usage

Run the file.
```bash
cd train_files
python ResEmoteNet_train.py
```

## Checkpoints
All of the checkpoint models for FER2013 can be found [here](https://drive.google.com/drive/folders/1Daxa6d1-XFxxpg6dyxYl4V-anfiHwtqK?usp=sharing).

## Results

 - FER2013:
   - Testing Accuracy: **79.79%** (SoTA - 76.82%)


## License

This repository is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.
=======
# 
ð“”ð“¶ð“¸ð“½ð“²ð“¦ð“ªð“¿ð“® : ð“¡ð“²ð“­ð“® ð“½ð“±ð“® ð“£ð“²ð“­ð“® ð“¸ð“¯ ð“—ð“¾ð“¶ð“ªð“· ð“”ð”ð“¹ð“»ð“®ð“¼ð“¼ð“²ð“¸ð“·ð“¼ðŸ˜Š

ðŸ“– ð‘¶ð’—ð’†ð’“ð’—ð’Šð’†ð’˜

This project showcases a Facial Emotion Detection System built using the ResEmotiNet model trained on the FER2013 dataset. The system can identify emotions from images, videos, and live webcam feeds, offering real-time emotion recognition functionality.

The system recognizes the following 7 emotions:

Happiness ðŸ˜€

Surprise ðŸ˜¦

Anger ðŸ˜ 

Sadness â˜¹ï¸

Disgust ðŸ¤¢

Fear ðŸ˜¨

Neutral ðŸ˜

A Streamlit interface provides an intuitive user experience, allowing users to upload images or videos or process live webcam feeds seamlessly.

ðŸ”§ ð‘­ð’†ð’‚ð’•ð’–ð’“ð’†ð’”

Emotion Detection from Images: Upload an image to detect emotions in real-time.

Emotion Detection from Videos: Process video files to identify emotions in every detected face.

Live Webcam Feed: Use your webcam to detect and classify emotions dynamically.

Streamlit Interface: User-friendly web application for input and visualization.

Haar Cascade Classifier: Efficient face detection in images and videos.

Detailed Emotion Scores: Probability scores for each emotion displayed alongside the highest-confidence prediction.

ðŸ–¥ï¸ ð‘»ð’†ð’„ð’‰ð’ð’ð’ð’ð’ˆð’š ð‘ºð’•ð’‚ð’„ð’Œ

Core Components

Deep Learning Framework: PyTorch

Model: ResEmotiNet (a custom deep learning model)

Dataset: FER2013, containing 7 emotion classes

ð‘¨ð’…ð’…ð’Šð’•ð’Šð’ð’ð’‚ð’ ð‘³ð’Šð’ƒð’“ð’‚ð’“ð’Šð’†ð’”

OpenCV: For image and video processing, and webcam integration

Streamlit: Interactive user interface

Torchvision: For pre-processing and data transformations

ðŸ› ï¸ ð‘¯ð’ð’˜ ð‘°ð’• ð‘¾ð’ð’“ð’Œð’”

Face Detection:
The Haar Cascade Classifier detects faces in the input image or video frame.

Emotion Classification:
The detected face is passed through the ResEmotiNet model, which predicts emotion probabilities.

Visualization:
The detected emotion (with the highest confidence) and corresponding scores for all emotions are displayed on the output.

ðŸ“ ð‘¼ð’”ð’‚ð’ˆð’† ð‘°ð’ð’”ð’•ð’“ð’–ð’„ð’•ð’Šð’ð’ð’”

1.Create a Conda environment.

```bash

ð—°ð—¼ð—»ð—±ð—® ð—°ð—¿ð—²ð—®ð˜ð—² --ð—» "ð—³ð—²ð—¿"
ð—°ð—¼ð—»ð—±ð—® ð—®ð—°ð˜ð—¶ð˜ƒð—®ð˜ð—² ð—³ð—²ð—¿

```

2. Install Python v3.8 using Conda.
   
```bash

ð—°ð—¼ð—»ð—±ð—® ð—¶ð—»ð˜€ð˜ð—®ð—¹ð—¹ ð—½ð˜†ð˜ð—µð—¼ð—»=ðŸ¯.ðŸ´

```
3. Clone the Repository
   
```bash

ð—´ð—¶ð˜ ð—°ð—¹ð—¼ð—»ð—² ð—µð˜ð˜ð—½ð˜€://ð—´ð—¶ð˜ð—µð˜‚ð—¯.ð—°ð—¼ð—º/ð—®ð—¯ð—µð—¶ð—»ð—®ð˜†ð—®-ð—½ð—®ð—¶ð—¹ð—¹ð—®/ð—˜ð—ºð—¼ð˜ð—¶ð—ªð—®ð˜ƒð—²  
ð—°ð—± ð—˜ð—ºð—¼ð˜ð—¶ð—ªð—®ð˜ƒð—²

```

4. Install Dependencies

```bash

ð—½ð—¶ð—½ ð—¶ð—»ð˜€ð˜ð—®ð—¹ð—¹ -ð—¿ ð—¿ð—²ð—¾ð˜‚ð—¶ð—¿ð—²ð—ºð—²ð—»ð˜ð˜€.ð˜ð˜…ð˜

```

5. Run the file.

```bash

ð—°ð—± ð˜ð—¿ð—®ð—¶ð—»_ð—³ð—¶ð—¹ð—²ð˜€
ð—½ð˜†ð˜ð—µð—¼ð—» ð˜ð—¿ð—®ð—¶ð—».ð—½ð˜†

```

6. Run the Application

Launch the Streamlit app:

```bash

ð˜€ð˜ð—¿ð—²ð—®ð—ºð—¹ð—¶ð˜ ð—¿ð˜‚ð—» ð—˜ð—ºð—¼ð˜ð—¶ð—ªð—®ð˜ƒð—²_ð—®ð—½ð—½.ð—½ð˜†

```

ðŸ—‚ï¸ ð‘°ð’ð’‘ð’–ð’• ð‘´ð’ð’…ð’†ð’”

Image Upload: Drag and drop an image file into the interface for analysis.

Video Upload: Upload a video to process frame-by-frame emotion detection.

Webcam Input: Activate your webcam and see real-time emotion detection.

ðŸ“Š ð‘«ð’‚ð’•ð’‚ð’”ð’†ð’• ð‘°ð’ð’‡ð’ð’“ð’Žð’‚ð’•ð’Šð’ð’

The FER2013 dataset is widely used for facial expression recognition tasks. 
It includes:
35,887 grayscale images (48x48 pixels each)
7 emotion classes: Happiness, Surprise, Anger, Sadness, Disgust, Fear, and Neutral

ðŸ’» ð‘ºð’„ð’“ð’†ð’†ð’ð’”ð’‰ð’ð’•ð’”

Image Input: Emotion detection and probabilities displayed on the processed image.

Video Input: Real-time video frame processing with emotion labels.

Webcam Feed: Live detection with bounding boxes and emotion predictions.

ðŸŒŸ ð‘¨ð’„ð’Œð’ð’ð’˜ð’ð’†ð’…ð’ˆð’†ð’Žð’†ð’ð’•ð’”

FER2013 Dataset: FER2013 Kaggle

OpenCV Library for efficient image processing

Streamlit for an interactive interface
>>>>>>> 886913494ea0d0dbc178e72b91cc2989d7c0b93f
